{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray import tune\n",
    "from ray import air\n",
    "from ray.tune import CLIReporter\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from hyperparameter import hp\n",
    "from ray.tune.search.hyperopt import HyperOptSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def train(config):\n",
    "    for epoch in range(10):\n",
    "        loss = 1/(epoch+1) + (0.001-config[\"lr\"])**2 + config[\"weight_decay\"]\n",
    "        tune.report(loss=loss)\n",
    "\n",
    "def train_noray(config):\n",
    "    for epoch in range(10):\n",
    "        loss = 1/(epoch+1) + (0.001-config[\"lr\"])**2 + config[\"weight_decay\"]\n",
    "        print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.00001444\n",
      "0.50001444\n",
      "0.3333477733333333\n",
      "0.25001444\n",
      "0.20001444000000002\n",
      "0.16668110666666666\n",
      "0.14287158285714285\n",
      "0.12501444\n",
      "0.11112555111111111\n",
      "0.10001444000000001\n"
     ]
    }
   ],
   "source": [
    "train_noray({\"lr\":0.0048,\"weight_decay\":0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2023-04-21 23:29:32</td></tr>\n",
       "<tr><td>Running for: </td><td>00:00:04.89        </td></tr>\n",
       "<tr><td>Memory:      </td><td>28.3/125.8 GiB     </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using AsyncHyperBand: num_stopped=20<br>Bracket: Iter 8.000: -0.1819232559062427 | Iter 4.000: -0.3069232559062427 | Iter 2.000: -0.5639545003350482 | Iter 1.000: -1.1112957645832158<br>Resources requested: 0/32 CPUs, 0/4 GPUs, 0.0/66.97 GiB heap, 0.0/32.69 GiB objects (0.0/1.0 accelerator_type:G)\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name    </th><th>status    </th><th>loc                   </th><th style=\"text-align: right;\">         lr</th><th style=\"text-align: right;\">  weight_decay</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_1fefd82b</td><td>TERMINATED</td><td>128.232.65.165:1805216</td><td style=\"text-align: right;\">0.000968365</td><td style=\"text-align: right;\">    0.081047  </td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">     0.201379   </td><td style=\"text-align: right;\">0.181047</td></tr>\n",
       "<tr><td>train_62599bf4</td><td>TERMINATED</td><td>128.232.65.165:1805373</td><td style=\"text-align: right;\">6.84128e-05</td><td style=\"text-align: right;\">    0.0750926 </td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">     0.0237603  </td><td style=\"text-align: right;\">0.575094</td></tr>\n",
       "<tr><td>train_07c21ac4</td><td>TERMINATED</td><td>128.232.65.165:1805375</td><td style=\"text-align: right;\">0.000383086</td><td style=\"text-align: right;\">    0.0583192 </td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">     0.128351   </td><td style=\"text-align: right;\">0.15832 </td></tr>\n",
       "<tr><td>train_1fcf78e1</td><td>TERMINATED</td><td>128.232.65.165:1805377</td><td style=\"text-align: right;\">0.011408   </td><td style=\"text-align: right;\">    0.0397098 </td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">     0.117607   </td><td style=\"text-align: right;\">0.139818</td></tr>\n",
       "<tr><td>train_af84a23c</td><td>TERMINATED</td><td>128.232.65.165:1805216</td><td style=\"text-align: right;\">0.015503   </td><td style=\"text-align: right;\">    0.179394  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.000255585</td><td style=\"text-align: right;\">1.1796  </td></tr>\n",
       "<tr><td>train_192ddd78</td><td>TERMINATED</td><td>128.232.65.165:1805216</td><td style=\"text-align: right;\">0.00200937 </td><td style=\"text-align: right;\">    0.230747  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.000152349</td><td style=\"text-align: right;\">1.23075 </td></tr>\n",
       "<tr><td>train_98e2809e</td><td>TERMINATED</td><td>128.232.65.165:1805216</td><td style=\"text-align: right;\">0.0124649  </td><td style=\"text-align: right;\">    0.204167  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.000288248</td><td style=\"text-align: right;\">1.2043  </td></tr>\n",
       "<tr><td>train_b4122c0d</td><td>TERMINATED</td><td>128.232.65.165:1805216</td><td style=\"text-align: right;\">0.000152631</td><td style=\"text-align: right;\">    0.0757841 </td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">     0.056484   </td><td style=\"text-align: right;\">0.175785</td></tr>\n",
       "<tr><td>train_4a4374ce</td><td>TERMINATED</td><td>128.232.65.165:1805216</td><td style=\"text-align: right;\">0.00821737 </td><td style=\"text-align: right;\">    0.241739  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.000173569</td><td style=\"text-align: right;\">1.24179 </td></tr>\n",
       "<tr><td>train_b621d82a</td><td>TERMINATED</td><td>128.232.65.165:1805216</td><td style=\"text-align: right;\">0.0175602  </td><td style=\"text-align: right;\">    0.0636803 </td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">     0.0731621  </td><td style=\"text-align: right;\">0.163955</td></tr>\n",
       "<tr><td>train_52e75ce7</td><td>TERMINATED</td><td>128.232.65.165:1805216</td><td style=\"text-align: right;\">7.40001e-05</td><td style=\"text-align: right;\">    0.259624  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.000233173</td><td style=\"text-align: right;\">1.25963 </td></tr>\n",
       "<tr><td>train_68085766</td><td>TERMINATED</td><td>128.232.65.165:1805216</td><td style=\"text-align: right;\">0.000195354</td><td style=\"text-align: right;\">    0.0197505 </td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">     0.0595241  </td><td style=\"text-align: right;\">0.119751</td></tr>\n",
       "<tr><td>train_37af125c</td><td>TERMINATED</td><td>128.232.65.165:1805216</td><td style=\"text-align: right;\">0.000123241</td><td style=\"text-align: right;\">    0.00242183</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">     0.183447   </td><td style=\"text-align: right;\">0.102423</td></tr>\n",
       "<tr><td>train_ef3c3fe1</td><td>TERMINATED</td><td>128.232.65.165:1805216</td><td style=\"text-align: right;\">0.000201298</td><td style=\"text-align: right;\">    0.0555263 </td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">     0.153149   </td><td style=\"text-align: right;\">0.155527</td></tr>\n",
       "<tr><td>train_aa7c3d6f</td><td>TERMINATED</td><td>128.232.65.165:1805216</td><td style=\"text-align: right;\">0.0192094  </td><td style=\"text-align: right;\">    0.156638  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.000178576</td><td style=\"text-align: right;\">1.15697 </td></tr>\n",
       "<tr><td>train_720d46d5</td><td>TERMINATED</td><td>128.232.65.165:1805216</td><td style=\"text-align: right;\">0.000453832</td><td style=\"text-align: right;\">    0.257047  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.000171185</td><td style=\"text-align: right;\">1.25705 </td></tr>\n",
       "<tr><td>train_979c46b6</td><td>TERMINATED</td><td>128.232.65.165:1805216</td><td style=\"text-align: right;\">0.00923261 </td><td style=\"text-align: right;\">    0.16137   </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.000213385</td><td style=\"text-align: right;\">1.16144 </td></tr>\n",
       "<tr><td>train_dabf5c02</td><td>TERMINATED</td><td>128.232.65.165:1805216</td><td style=\"text-align: right;\">0.000335171</td><td style=\"text-align: right;\">    0.141544  </td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">     0.032722   </td><td style=\"text-align: right;\">0.641545</td></tr>\n",
       "<tr><td>train_aaa05ef2</td><td>TERMINATED</td><td>128.232.65.165:1805216</td><td style=\"text-align: right;\">0.000847081</td><td style=\"text-align: right;\">    0.0787648 </td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">     0.0326858  </td><td style=\"text-align: right;\">0.578765</td></tr>\n",
       "<tr><td>train_8e28f101</td><td>TERMINATED</td><td>128.232.65.165:1805216</td><td style=\"text-align: right;\">0.00865107 </td><td style=\"text-align: right;\">    0.254846  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.000234842</td><td style=\"text-align: right;\">1.2549  </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-21 23:29:24,687\tINFO worker.py:1553 -- Started a local Ray instance.\n",
      "/local/scratch-3/fwe21/miniconda3/envs/torch/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name    </th><th>date               </th><th>done  </th><th>episodes_total  </th><th>experiment_id                   </th><th>hostname          </th><th style=\"text-align: right;\">  iterations_since_restore</th><th style=\"text-align: right;\">   loss</th><th>node_ip       </th><th style=\"text-align: right;\">    pid</th><th style=\"text-align: right;\">  time_since_restore</th><th style=\"text-align: right;\">  time_this_iter_s</th><th style=\"text-align: right;\">  time_total_s</th><th style=\"text-align: right;\">  timestamp</th><th style=\"text-align: right;\">  timesteps_since_restore</th><th>timesteps_total  </th><th style=\"text-align: right;\">  training_iteration</th><th>trial_id  </th><th style=\"text-align: right;\">  warmup_time</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_1fefd82b</td><td>2023-04-21_23-29-29</td><td>False </td><td>                </td><td>1e82ddcfe54c4917acf63ea395d472a7</td><td>beyla.cl.cam.ac.uk</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">1.08105</td><td>128.232.65.165</td><td style=\"text-align: right;\">1805216</td><td style=\"text-align: right;\">         0.000281334</td><td style=\"text-align: right;\">       0.000281334</td><td style=\"text-align: right;\">   0.000281334</td><td style=\"text-align: right;\"> 1682116169</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>1fefd82b  </td><td style=\"text-align: right;\">    0.0054009</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-21 23:29:32,539\tINFO tune.py:798 -- Total run time: 6.16 seconds (4.75 seconds for the tuning loop).\n"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    \"lr\": tune.loguniform(1e-4, 1e-1),\n",
    "    \"weight_decay\": tune.uniform(0,0.3)\n",
    "}\n",
    "\n",
    "scheduler = ASHAScheduler(\n",
    "    max_t=10,\n",
    "    grace_period=1,\n",
    "    reduction_factor=2)\n",
    "\n",
    "hyperopt_search = HyperOptSearch(metric=\"loss\", mode=\"min\")\n",
    "\n",
    "tuner = tune.Tuner(\n",
    "    tune.with_resources(\n",
    "        tune.with_parameters(train),\n",
    "        resources={\"cpu\": 2, \"gpu\": 1}\n",
    "    ),\n",
    "    tune_config=tune.TuneConfig(\n",
    "        search_alg=hyperopt_search,\n",
    "        metric=\"loss\",\n",
    "        mode=\"min\",\n",
    "        scheduler=scheduler,\n",
    "        num_samples=100,\n",
    "    ),\n",
    "    param_space=config,\n",
    ")\n",
    "results = tuner.fit()\n",
    "\n",
    "best_result = results.get_best_result(\"loss\", \"min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Result(metrics={'loss': 0.10242259753980555, 'done': True, 'trial_id': '37af125c', 'experiment_tag': '13_lr=0.0001,weight_decay=0.0024'}, error=None, log_dir=PosixPath('/home/fwe21/ray_results/train_2023-04-21_23-29-22/train_37af125c_13_lr=0.0001,weight_decay=0.0024_2023-04-21_23-29-30'))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2023-04-23 19:59:08</td></tr>\n",
       "<tr><td>Running for: </td><td>00:00:28.65        </td></tr>\n",
       "<tr><td>Memory:      </td><td>29.3/125.8 GiB     </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Resources requested: 0/32 CPUs, 0/4 GPUs, 0.0/66.84 GiB heap, 0.0/32.64 GiB objects (0.0/1.0 accelerator_type:G)\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name              </th><th>status    </th><th>loc                   </th><th style=\"text-align: right;\">  scaling_config/num_w\n",
       "orkers</th><th style=\"text-align: right;\">  train_loop_config/ba\n",
       "tch_size</th><th style=\"text-align: right;\">  train_loop_config/hi\n",
       "dden_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  _timestamp</th><th style=\"text-align: right;\">  _time_this_iter_s</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>TorchTrainer_dc4a4_00000</td><td>TERMINATED</td><td>128.232.65.165:2071096</td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\">8</td><td style=\"text-align: right;\">2</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         5.99308</td><td style=\"text-align: right;\">0.128346</td><td style=\"text-align: right;\">  1682276333</td><td style=\"text-align: right;\">           0.240674</td></tr>\n",
       "<tr><td>TorchTrainer_dc4a4_00001</td><td>TERMINATED</td><td>128.232.65.165:2070914</td><td style=\"text-align: right;\">2</td><td style=\"text-align: right;\">4</td><td style=\"text-align: right;\">2</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         7.03432</td><td style=\"text-align: right;\">0.198105</td><td style=\"text-align: right;\">  1682276330</td><td style=\"text-align: right;\">           0.310543</td></tr>\n",
       "<tr><td>TorchTrainer_dc4a4_00002</td><td>TERMINATED</td><td>128.232.65.165:2071720</td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\">8</td><td style=\"text-align: right;\">2</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         5.92824</td><td style=\"text-align: right;\">0.17264 </td><td style=\"text-align: right;\">  1682276343</td><td style=\"text-align: right;\">           0.230762</td></tr>\n",
       "<tr><td>TorchTrainer_dc4a4_00003</td><td>TERMINATED</td><td>128.232.65.165:2071823</td><td style=\"text-align: right;\">2</td><td style=\"text-align: right;\">8</td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         6.43302</td><td style=\"text-align: right;\">0.166028</td><td style=\"text-align: right;\">  1682276346</td><td style=\"text-align: right;\">           0.261349</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-23 19:58:40,302\tINFO data_parallel_trainer.py:319 -- GPUs are detected in your Ray cluster, but GPU training is not enabled for this trainer. To enable GPU training, make sure to set `use_gpu` to True in your scaling config.\n",
      "2023-04-23 19:58:40,309\tINFO data_parallel_trainer.py:319 -- GPUs are detected in your Ray cluster, but GPU training is not enabled for this trainer. To enable GPU training, make sure to set `use_gpu` to True in your scaling config.\n",
      "2023-04-23 19:58:40,309\tINFO data_parallel_trainer.py:319 -- GPUs are detected in your Ray cluster, but GPU training is not enabled for this trainer. To enable GPU training, make sure to set `use_gpu` to True in your scaling config.\n",
      "\u001b[2m\u001b[36m(TrainTrainable pid=2070914)\u001b[0m 2023-04-23 19:58:43,877\tINFO data_parallel_trainer.py:319 -- GPUs are detected in your Ray cluster, but GPU training is not enabled for this trainer. To enable GPU training, make sure to set `use_gpu` to True in your scaling config.\n",
      "\u001b[2m\u001b[36m(TorchTrainer pid=2070914)\u001b[0m 2023-04-23 19:58:43,886\tINFO data_parallel_trainer.py:319 -- GPUs are detected in your Ray cluster, but GPU training is not enabled for this trainer. To enable GPU training, make sure to set `use_gpu` to True in your scaling config.\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=2071097)\u001b[0m 2023-04-23 19:58:47,339\tINFO config.py:86 -- Setting up process group for: env:// [rank=0, world_size=2]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=2071097)\u001b[0m 2023-04-23 19:58:47,467\tINFO train_loop_utils.py:255 -- Moving model to device: cpu\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=2071097)\u001b[0m 2023-04-23 19:58:47,467\tINFO train_loop_utils.py:315 -- Wrapping provided model in DistributedDataParallel.\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=2071097)\u001b[0m /local/scratch-3/fwe21/miniconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([4, 1])) that is different to the input size (torch.Size([4, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=2071097)\u001b[0m   return F.mse_loss(input, target, reduction=self.reduction)\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=2071098)\u001b[0m /local/scratch-3/fwe21/miniconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([4, 1])) that is different to the input size (torch.Size([4, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=2071098)\u001b[0m   return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RayTrainWorker pid=2071502)\u001b[0m 2023-04-23 19:58:51,040\tINFO config.py:86 -- Setting up process group for: env:// [rank=0, world_size=1]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=2071502)\u001b[0m 2023-04-23 19:58:51,115\tINFO train_loop_utils.py:255 -- Moving model to device: cpu\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=2071502)\u001b[0m /local/scratch-3/fwe21/miniconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([8, 1])) that is different to the input size (torch.Size([8, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=2071502)\u001b[0m   return F.mse_loss(input, target, reduction=self.reduction)\n",
      "2023-04-23 19:58:53,556\tINFO data_parallel_trainer.py:319 -- GPUs are detected in your Ray cluster, but GPU training is not enabled for this trainer. To enable GPU training, make sure to set `use_gpu` to True in your scaling config.\n",
      "2023-04-23 19:58:56,318\tINFO data_parallel_trainer.py:319 -- GPUs are detected in your Ray cluster, but GPU training is not enabled for this trainer. To enable GPU training, make sure to set `use_gpu` to True in your scaling config.\n",
      "\u001b[2m\u001b[36m(TrainTrainable pid=2071720)\u001b[0m 2023-04-23 19:58:57,357\tINFO data_parallel_trainer.py:319 -- GPUs are detected in your Ray cluster, but GPU training is not enabled for this trainer. To enable GPU training, make sure to set `use_gpu` to True in your scaling config.\n",
      "\u001b[2m\u001b[36m(TorchTrainer pid=2071720)\u001b[0m 2023-04-23 19:58:57,366\tINFO data_parallel_trainer.py:319 -- GPUs are detected in your Ray cluster, but GPU training is not enabled for this trainer. To enable GPU training, make sure to set `use_gpu` to True in your scaling config.\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=2072068)\u001b[0m 2023-04-23 19:59:03,750\tINFO config.py:86 -- Setting up process group for: env:// [rank=0, world_size=2]\n",
      "2023-04-23 19:59:08,949\tINFO tune.py:798 -- Total run time: 28.77 seconds (28.60 seconds for the tuning loop).\n"
     ]
    }
   ],
   "source": [
    "from ray import tune\n",
    "from ray.tune import Tuner\n",
    "from ray.train.examples.pytorch.torch_linear_example import (\n",
    "    train_func as linear_train_func,\n",
    ")\n",
    "from ray.train.torch import TorchTrainer\n",
    "from ray import air\n",
    "\n",
    "trainer = TorchTrainer(\n",
    "    train_loop_per_worker=linear_train_func,\n",
    "    train_loop_config={\"lr\": 1e-2, \"batch_size\": 4, \"epochs\": 10},\n",
    "    scaling_config=air.config.ScalingConfig(num_workers=1, use_gpu=False),\n",
    ")\n",
    "\n",
    "param_space = {\n",
    "    # The params will be merged with the ones defined in the TorchTrainer\n",
    "    \"train_loop_config\": {\n",
    "        # This is a parameter that hasn't been set in the TorchTrainer\n",
    "        \"hidden_size\": tune.randint(1, 4),\n",
    "        # This will overwrite whatever was set when TorchTrainer was instantiated\n",
    "        \"batch_size\": tune.choice([4, 8]),\n",
    "    },\n",
    "    # Tune the number of distributed workers\n",
    "    \"scaling_config\": air.config.ScalingConfig(num_workers=tune.grid_search([1, 2])),\n",
    "}\n",
    "\n",
    "tuner = Tuner(\n",
    "    trainable=trainer,\n",
    "    run_config=air.RunConfig(name=\"test_tuner\", local_dir=\"~/ray_results\"),\n",
    "    param_space=param_space,\n",
    "    tune_config=tune.TuneConfig(\n",
    "        mode=\"min\", metric=\"loss\", num_samples=2, max_concurrent_trials=2\n",
    "    ),\n",
    ")\n",
    "result_grid = tuner.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
