{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/scratch-3/fwe21/miniconda3/envs/torch/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "from process_results.results_utils import DATASETS, DEFAULT_METRIC, to_dataframe, make_plots, read_log, f, plot_repeats\n",
    "\n",
    "def plot_heatmap(df):\n",
    "    df[\"score_str\"] =  df.best_metric.map(lambda x: f\"{x*100:.1f}\\n\") + df.last3_mean.map(lambda x: f\"{x*100:.1f}\") + df.last3_std.map(lambda x: f\" ± {x*100:.1f}\")\n",
    "    sns.heatmap(df.pivot(\"lr\",\"batch_size\",\"best_metric\"), annot=df.pivot(\"lr\",\"batch_size\",\"score_str\"),fmt=\"\")\n",
    "    plt.show()\n",
    "\n",
    "def logfile_paths(dataset):\n",
    "    return glob.glob(f\"../../checkpoints/finetune/bert_base/{dataset}/**/log\",recursive=True)\n",
    "\n",
    "# for dataset in DATASETS:\n",
    "#     for logfile in logfile_paths(dataset):\n",
    "#         df = to_dataframe(logfile, metric=DEFAULT_METRIC[dataset])\n",
    "#         plot_heatmap(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for dataset in DATASETS:\n",
    "#     score = to_dataframe(logfile_paths(dataset)[0], metric=DEFAULT_METRIC[dataset])[\"best_metric\"].max()\n",
    "#     print(f\"{dataset}: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in DATASETS:\n",
    "    print(dataset)\n",
    "    for logfile in glob.glob(f\"../../checkpoints/finetune/bert_base/{dataset}/log*\"):\n",
    "        df = to_dataframe(logfile, metric=DEFAULT_METRIC[dataset])\n",
    "        if \"best_metric\" in df:\n",
    "            print(df[\"best_metric\"].max(),logfile)\n",
    "            make_plots(logfile, metric=DEFAULT_METRIC[dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QNLI\n",
      "[0.8833974006955885, 0.8861431447922387, 0.8835804503020318, 0.8865092440051254]\n",
      "\\textbf{88.7} (88.5{\\footnotesize±0.1})\n",
      "RTE\n",
      "[0.6534296028880866, 0.6173285198555957, 0.6101083032490975, 0.6498194945848376]\n",
      "\\textbf{65.3} (63.3{\\footnotesize±1.9})\n",
      "SST-2\n",
      "[0.8979357798165137, 0.8944954128440367, 0.9002293577981652, 0.8922018348623854]\n",
      "\\textbf{90.0} (89.6{\\footnotesize±0.3})\n",
      "MRPC\n",
      "[0.808695652173913, 0.8139130434782609, 0.8028985507246377, 0.8133333333333334]\n",
      "\\textbf{81.4} (81.0{\\footnotesize±0.4})\n",
      "MNLI\n",
      "Fail MNLI\n",
      "QQP\n",
      "[0.8656756281852722, 0.8658441305160522, 0.8669000864028931, 0.8661304116249084]\n",
      "\\textbf{86.7} (86.6{\\footnotesize±0.0})\n",
      "CoLA\n",
      "[0.4762446880340576, 0.4328077733516693, 0.4328095614910126, 0.43856924772262573]\n",
      "\\textbf{47.6} (44.5{\\footnotesize±1.8})\n"
     ]
    }
   ],
   "source": [
    "for dataset in DATASETS:\n",
    "    try:\n",
    "        plot_repeats(dataset,\n",
    "            f\"../../checkpoints/finetune/bert-medium/{dataset}/log_hp*\",\n",
    "            f\"../../checkpoints/finetune/bert-medium/{dataset}/log_rp*\"\n",
    "        )\n",
    "    except:\n",
    "        print(\"Fail\",dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QNLI\n",
      "[0.9125022888183594]\n",
      "\\textbf{91.3} (91.3{\\footnotesize±0.0})\n",
      "RTE\n",
      "[0.7111913561820984, 0.6714801444043321, 0.6498194945848376, 0.6967509025270758]\n",
      "\\textbf{71.1} (68.2{\\footnotesize±2.4})\n",
      "SST-2\n",
      "[0.9346330275229358, 0.9277522935779816, 0.9311926605504587, 0.9254587155963303]\n",
      "\\textbf{93.5} (93.0{\\footnotesize±0.3})\n",
      "MRPC\n",
      "[0.8434782608695652, 0.8382608695652174, 0.8417391304347827]\n",
      "\\textbf{84.3} (84.1{\\footnotesize±0.2})\n",
      "MNLI\n",
      "[0.8472745797249108, 0.8472746014595032, 0.8423841059602649, 0.8404482934284259]\n",
      "\\textbf{84.7} (84.4{\\footnotesize±0.3})\n",
      "QQP\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/local-zfs/fwe21/project/knowledge-distillation-transformers/process_results/finetuning.ipynb Cell 5\u001b[0m in \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bbeyla.cl.cam.ac.uk/local-zfs/fwe21/project/knowledge-distillation-transformers/process_results/finetuning.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m dataset \u001b[39min\u001b[39;00m DATASETS:\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bbeyla.cl.cam.ac.uk/local-zfs/fwe21/project/knowledge-distillation-transformers/process_results/finetuning.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m     plot_repeats(dataset,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bbeyla.cl.cam.ac.uk/local-zfs/fwe21/project/knowledge-distillation-transformers/process_results/finetuning.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m         \u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m../../checkpoints/finetune/bert_base/\u001b[39;49m\u001b[39m{\u001b[39;49;00mdataset\u001b[39m}\u001b[39;49;00m\u001b[39m/log\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bbeyla.cl.cam.ac.uk/local-zfs/fwe21/project/knowledge-distillation-transformers/process_results/finetuning.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m         \u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m../../checkpoints/finetune/bert_base/\u001b[39;49m\u001b[39m{\u001b[39;49;00mdataset\u001b[39m}\u001b[39;49;00m\u001b[39m/log_rp*\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bbeyla.cl.cam.ac.uk/local-zfs/fwe21/project/knowledge-distillation-transformers/process_results/finetuning.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m     )\n",
      "File \u001b[0;32m/local-zfs/fwe21/project/knowledge-distillation-transformers/process_results/results_utils.py:157\u001b[0m, in \u001b[0;36mplot_repeats\u001b[0;34m(dataset, hp_path, rp_path, plot)\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[39mreturn\u001b[39;00m eval_res[\u001b[39m\"\u001b[39m\u001b[39mdev_accuracy\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    156\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(training_runs_rp)\u001b[39m==\u001b[39m\u001b[39m0\u001b[39m:\n\u001b[0;32m--> 157\u001b[0m     training_runs_rp\u001b[39m.\u001b[39mappend(\u001b[39mmax\u001b[39m([(\u001b[39mmax\u001b[39m(get_score(eval_res) \u001b[39mfor\u001b[39;00m eval_res \u001b[39min\u001b[39;00m run\u001b[39m.\u001b[39mepoch_evals),run) \u001b[39mfor\u001b[39;00m run \u001b[39min\u001b[39;00m training_runs_hp],key\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m x:x[\u001b[39m0\u001b[39m])[\u001b[39m1\u001b[39m])\n\u001b[1;32m    158\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    159\u001b[0m     \u001b[39mfor\u001b[39;00m run \u001b[39min\u001b[39;00m training_runs_hp:\n",
      "File \u001b[0;32m/local-zfs/fwe21/project/knowledge-distillation-transformers/process_results/results_utils.py:157\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[39mreturn\u001b[39;00m eval_res[\u001b[39m\"\u001b[39m\u001b[39mdev_accuracy\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    156\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(training_runs_rp)\u001b[39m==\u001b[39m\u001b[39m0\u001b[39m:\n\u001b[0;32m--> 157\u001b[0m     training_runs_rp\u001b[39m.\u001b[39mappend(\u001b[39mmax\u001b[39m([(\u001b[39mmax\u001b[39;49m(get_score(eval_res) \u001b[39mfor\u001b[39;49;00m eval_res \u001b[39min\u001b[39;49;00m run\u001b[39m.\u001b[39;49mepoch_evals),run) \u001b[39mfor\u001b[39;00m run \u001b[39min\u001b[39;00m training_runs_hp],key\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m x:x[\u001b[39m0\u001b[39m])[\u001b[39m1\u001b[39m])\n\u001b[1;32m    158\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    159\u001b[0m     \u001b[39mfor\u001b[39;00m run \u001b[39min\u001b[39;00m training_runs_hp:\n",
      "File \u001b[0;32m/local-zfs/fwe21/project/knowledge-distillation-transformers/process_results/results_utils.py:157\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[39mreturn\u001b[39;00m eval_res[\u001b[39m\"\u001b[39m\u001b[39mdev_accuracy\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    156\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(training_runs_rp)\u001b[39m==\u001b[39m\u001b[39m0\u001b[39m:\n\u001b[0;32m--> 157\u001b[0m     training_runs_rp\u001b[39m.\u001b[39mappend(\u001b[39mmax\u001b[39m([(\u001b[39mmax\u001b[39m(get_score(eval_res) \u001b[39mfor\u001b[39;00m eval_res \u001b[39min\u001b[39;00m run\u001b[39m.\u001b[39mepoch_evals),run) \u001b[39mfor\u001b[39;00m run \u001b[39min\u001b[39;00m training_runs_hp],key\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m x:x[\u001b[39m0\u001b[39m])[\u001b[39m1\u001b[39m])\n\u001b[1;32m    158\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    159\u001b[0m     \u001b[39mfor\u001b[39;00m run \u001b[39min\u001b[39;00m training_runs_hp:\n",
      "File \u001b[0;32m/local-zfs/fwe21/project/knowledge-distillation-transformers/process_results/results_utils.py:153\u001b[0m, in \u001b[0;36mplot_repeats.<locals>.get_score\u001b[0;34m(eval_res)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[39mreturn\u001b[39;00m eval_res[\u001b[39m\"\u001b[39m\u001b[39mdev_metrics\u001b[39m\u001b[39m\"\u001b[39m][DEFAULT_METRIC[dataset]]\n\u001b[1;32m    152\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 153\u001b[0m     \u001b[39massert\u001b[39;00m DEFAULT_METRIC[dataset] \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    154\u001b[0m     \u001b[39mreturn\u001b[39;00m eval_res[\u001b[39m\"\u001b[39m\u001b[39mdev_accuracy\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for dataset in DATASETS:\n",
    "    if dataset == \"QQP\":\n",
    "        continue\n",
    "    plot_repeats(dataset,\n",
    "        f\"../../checkpoints/finetune/bert_base/{dataset}/log_hp*\",\n",
    "        f\"../../checkpoints/finetune/bert_base/{dataset}/log_rp*\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
